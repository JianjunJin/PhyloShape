#!/usr/bin/env python

"""Simulate an artifical beak dataset.

Two phenotypes are simulated from randomly drawn parameters and their
common ancestor is modeled as having an exactly intermediate phenotype,
defined as being generated by the parameter set that is the average of
the two descendant taxa parameter sets. Divergence from the common
ancestor is modeled to increase linear with time in this example
(though not Brownian) and so intermediate ancestral samples along each
branch can be sampled using np.linspace(ancestor, descendant, 2 +
number of internal samples).

- (405, 5) sets of unique combinations of 5 simulation parameters.
- 81,810 pairs (n-choose-2) ways of sampling two param sets.
- (81810, 55) df with pair params and 9 ancestors with intermediate scaled params.
- Files: params df = simulation_params.csv; tree = simulation_tree.nwk

/parent
/parent/simulation_tree.nwk
/parent/simulation_params.csv
/parent/dset[x]/
/parent/dset[x]/node[y]_coords.csv

"""

from typing import Mapping
from pathlib import Path
import toytree
import itertools
import pandas as pd
import numpy as np
from phyloshape.simulate.landmarks import get_beak_landmarks

# LABELS = ["length", "rotation", "curve_x", "curve_y", "beak_radius_start"]
LABELS = ["length", "rotation", "curve_x", "curve_y"]


def get_parameter_grid() -> np.ndarray:
    """Return array of horn shapes generated by grid x 5 parameters.

    Cannot allow very strong curve and very short beak, or weird shapes
    arise that can intersect themselves.
    """
    params = np.array(list(itertools.product(
        np.linspace(1, 7, 3),                 # length @ 3 points
        # np.linspace(-1.5 * np.pi, 1.5 * np.pi, 5),  # rotation @ 5 points
        np.linspace(0, 2 * np.pi, 3),                 # rotation @ 3
        np.linspace(-0.75, 0.75, 3),                  # curve_x @ 3 points
        np.linspace(-0.75, 0.75, 3),                  # curve_y @ 3 points
        #np.linspace(0.5, 1.5, 3),               # beak_radius_start @ 3 points
    )))
    return params


def get_tree_with_sampled_ancestors(n_ancestors: int) -> toytree.ToyTree:
    """Return a 2-tip tree with sampled ancestor Nodes along edges.
    """
    tree = toytree.rtree.unittree(ntips=2, treeheight=1)
    tree[0].name = "A"
    tree[1].name = "B"
    tree[-1].name = "AB"

    anc_count = range(n_ancestors, 0, -1)
    anc_times = np.linspace(1, 0, n_ancestors + 2)[1:-1]
    for idx, time in zip(anc_count, anc_times):
        for node in tree[:tree.ntips]:
            name = node.name
            tree = tree.mod.add_internal_node(
                name, name=f"{name}anc{idx}", dist=time)
    return tree


def get_parameter_dataframe(tree: toytree.ToyTree, params: np.ndarray) -> pd.DataFrame:
    """Return df with parameters of two diverged horn shapes, their
    common ancestor, and any ancestors sampled along branches.
    """
    # ways to sample 2 shapes from params grid without replacement
    pairs = list(itertools.combinations(params, 2))

    # TESTING: subsample
    # pairs = pairs[:10]

    # zeros array to store params for all nodes
    arr = np.zeros(shape=(len(pairs), tree.nnodes * len(LABELS)))

    # create labels with node names appended
    labels = [[f"{node.name}-{i}" for i in LABELS] for node in tree]
    labels = list(itertools.chain(*labels))

    # create dataframe with labeled columns from array
    frame = pd.DataFrame(arr, columns=labels)

    # calculate ancestral node parameter values
    n_params = params.shape[1]
    n_ancestors = tree.distance.get_node_distance("A", "AB", topology_only=True) - 1
    for idx, pair in enumerate(pairs):
        params_ab = np.mean(pair, axis=0)
        params_a = pair[0]
        params_b = pair[1]
        params_a_ancestors = np.linspace(params_a, params_ab, n_ancestors + 2)[1:-1]
        params_b_ancestors = np.linspace(params_b, params_ab, n_ancestors + 2)[1:-1]

        # enter data for A
        ii = 0
        frame.iloc[idx, ii:ii + n_params] = params_a
        ii += n_params
        frame.iloc[idx, ii:ii + n_params] = params_b
        ii += n_params

        # enter data for A ancestors
        if n_ancestors:
            for anc in range(n_ancestors):
                frame.iloc[idx, ii: ii + n_params] = params_a_ancestors[anc]
                ii += n_params
        if n_ancestors:
            for anc in range(n_ancestors):
                frame.iloc[idx, ii: ii + n_params] = params_b_ancestors[anc]
                ii += n_params
        frame.iloc[idx, -n_params:] = params_ab
    return frame


def get_landmarks_dataframe(
    params: Mapping[str, float],
    num_intervals: int = 40,
    num_disc_points: int = 15,
) -> np.ndarray:
    """Return a 2D array with (x,y,z) coordinates given sim params.
    """
    arr = get_beak_landmarks(
        num_intervals=num_intervals,
        num_disc_points=num_disc_points,
        **params
    )

    # flatten to shape (idx, 3): (x, y, z)
    landmarks = arr.reshape((-1, 3))
    return landmarks


def other():
    """..."""
    #     # data['x'] = arr[:, 0]
    #     # print(arr.shape)

    #     # print(landmarks.shape)

    #     df = pd.DataFrame({
    #         'dataset': dataset,
    #         'sample_idx': row,
    #         'landmark': range(landmarks.shape[0]),
    #         'x': landmarks[:, 0],
    #         'y': landmarks[:, 1],
    #         'z': landmarks[:, 2],
    #     })
    #     full = pd.concat([full, df])


def write_data(
    name: str,
    directory: Path | str,
    allparams: pd.DataFrame,
) -> None:
    """
    """

    # get output directory
    parent = Path(directory)
    outdir = parent / name
    outdir.mkdir()

    # make a directory for every dataset
    # for 



# # write simulation parameters
# arr = pd.concat(params).reset_index(names="sample_idx")
# arr = arr[["dataset", "sample_idx"] + LABELS]
# arr.to_csv(f"./{NAME}_params.csv")
# print(arr)

# print(full.shape)
# print(full.reset_index(drop=True))
# full.to_csv(f"./{NAME}_landmarks.csv")


if __name__ == "__main__":

    # landmark sampling density
    NAME = "TEST"
    IVALS = 50
    DISCS = 20
    NMARKS = IVALS * DISCS

    # get all 405 simulation parameter combinations
    params = get_parameter_grid()
    paramsdf = pd.DataFrame(params, columns=LABELS)
    paramsdf.to_csv(f"../../simbeak/datasets/{NAME}_params.csv")
    print(params.shape)

    # get a 2D array of landmark coordinates for each model
    landmarks = np.zeros((NMARKS * len(params), 4))
    pdx = 0
    for idx, params_ in enumerate(params):
        params_ = dict(zip(LABELS, params_))
        points = get_landmarks_dataframe(
            params=params_, num_intervals=IVALS, num_disc_points=DISCS)
        landmarks[pdx:pdx + NMARKS, 1:] = points
        landmarks[pdx:pdx + NMARKS, 0] = idx
        pdx += NMARKS
    frame = pd.DataFrame(landmarks, columns=("dset", "x", "y", "z"))
    frame.infer_objects()
    frame.to_csv(f"../../simbeak/datasets/{NAME}_landmarks.csv")

    # get a tree w/ sampled ancestors on each branch and generate
    # interpolated param settings for all nodes on tree
    tree = get_tree_with_sampled_ancestors(4)
    tree.write(f"../../simbeak/datasets/{NAME}_tree.nwk")
    datasets = get_parameter_dataframe(tree, params)
    datasets.to_csv(f"../../simbeak/datasets/{NAME}_phylo_params.csv")

    # write each sim dataset to a different file
    parent = Path("../../simbeak/datasets/")
    outdir = parent / f"{NAME}_data"
    outdir.mkdir(exist_ok=True)
    for didx in range(datasets.shape[0]):
        # select a dataset and create an empty df
        dset = datasets.iloc[didx]
        landmarks = pd.DataFrame(
            np.zeros((NMARKS * tree.nnodes, 4)),
            columns=["node", "x", "y", "z"],
        )
        landmarks.node = landmarks.node.astype(pd.StringDtype())

        # simulate coords for each node
        pdx = 0
        groups = dset.groupby(lambda x: x.split("-")[0])
        for name, series in groups:

            params = dict(zip(LABELS, series.values))
            points = get_landmarks_dataframe(
                params=params_, num_intervals=IVALS, num_disc_points=DISCS)
            landmarks.iloc[pdx:pdx + NMARKS, 0] = name
            landmarks.iloc[pdx:pdx + NMARKS, 1:] = points
            pdx += NMARKS
        landmarks.to_csv(outdir / f"dset_{didx}.csv")

    print(landmarks.node.unique())
